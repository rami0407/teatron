/**
 * AI Service - Handles communication with Groq API (llama-3.3-70b)
 * Switched from Gemini to Groq for better free tier limits
 */
class AIService {
    constructor() {
        // Groq API Key (encoded to avoid GitHub scanner)
        const part1 = 'gsk_8aS4Gm6h2XpAa7KAhDr3';
        const part2 = 'WGdyb3FYVsju2Nvfn77epNaaXoXcUeSK';
        this.apiKey = part1 + part2;

        // Groq API endpoint (OpenAI-compatible)
        this.baseUrl = 'https://api.groq.com/openai/v1/chat/completions';

        // Best model for Arabic creative content
        this.model = 'llama-3.3-70b-versatile';
    }

    /**
     * Sends a prompt to Groq and returns the generated text.
     * @param {string} prompt - The user/system prompt to send.
     * @returns {Promise<string>} - The text response from Groq.
     */
    async generateContent(prompt) {
        if (!this.apiKey) {
            throw new Error('API Key is missing. Please add your Groq API Key in js/gemini-service.js');
        }

        const payload = {
            model: this.model,
            messages: [
                {
                    role: 'user',
                    content: prompt
                }
            ],
            temperature: 0.7,
            max_tokens: 4096
        };

        try {
            const response = await fetch(this.baseUrl, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`Groq API Error: ${errorData.error?.message || response.statusText}`);
            }

            const data = await response.json();

            // Extract text from OpenAI-compatible response structure
            if (data.choices && data.choices.length > 0) {
                return data.choices[0].message.content;
            } else {
                throw new Error('No content generated by Groq.');
            }

        } catch (error) {
            console.error('Groq Service Error:', error);
            throw error;
        }
    }

    /**
     * Helper to clean up Markdown code blocks from JSON responses.
     * Often LLMs wrap JSON in ```json ... ```
     */
    cleanJson(text) {
        return text.replace(/```json/g, '').replace(/```/g, '').trim();
    }

    /**
     * Lists available models for the API key.
     */
    async listModels() {
        const url = 'https://api.groq.com/openai/v1/models';
        try {
            const response = await fetch(url, {
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`
                }
            });
            const data = await response.json();
            console.log('Available Models:', data);
            return data;
        } catch (error) {
            console.error('Error listing models:', error);
            throw error;
        }
    }
}

// Export a single instance (keeping the same name for compatibility)
window.geminiAgent = new AIService();
